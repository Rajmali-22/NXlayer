================================================================================
                         AI TEXT BOT - DOCUMENTATION
================================================================================

SUMMARY
-------
AI Text Bot is an Electron desktop app that gives you AI-powered text help
where you type. It can fix grammar, continue writing, process clipboard content,
analyze screenshots with vision AI, and take voice input. You get an overlay
prompt bar, inline suggestion popup, and optional context-aware behavior (profile
+ app rules) and auto-inject (paste without confirming).

Features:
- System-wide keystroke monitoring with privacy filters (no banking/password apps)
- Overlay prompt with tone selection and voice input
- Multiple triggers: backtick (grammar fix), double-backtick (continue), clipboard,
  screenshot+vision, instruction text
- Context mode: profile (from resume) + app/URL rules → personalized, app-adapted prompts
- Auto-inject: generate then type/paste immediately (no popup step)
- Keyboard injection with humanize typing and pause (Ctrl+.)
- Voice-to-text (Google Speech Recognition)
- Screenshot + Vision (Anthropic Claude)

================================================================================

KEYBOARD SHORTCUTS
------------------

1. Ctrl+Shift+Space - TOGGLE OVERLAY
   Show or hide the main prompt window (bottom center).

2. Ctrl+Shift+P - PASTE GENERATED TEXT
   Accept the last suggestion and paste at cursor (after viewing in popup).
   If auto-inject is ON, this is not needed; text is injected automatically.

3. Ctrl+Alt+Enter - TRIGGER (BACKTICK / EXTENSION / INSTRUCTION)
   Sends current typed buffer to AI. Behavior depends on what you typed:
   - Plain text + trigger → grammar/spelling fix (backtick mode)
   - After a recent trigger with no new typing → continue writing (extension mode)
   - Command-like text (e.g. "translate to Spanish") + trigger → instruction mode
   Backspaces the buffer, then injects AI result.

4. Ctrl+Shift+D - CLIPBOARD TRIGGER
   - Clipboard only: AI auto-detects (code, email, question) and responds.
   - Type an instruction first (e.g. "summarize"), then Ctrl+Shift+D:
     instruction is sent with clipboard; instruction text is backspaced, result injected.

5. Ctrl+Shift+F - SCREENSHOT + VISION
   Captures screen, sends to Anthropic Vision with optional instruction.
   Type instruction in the popup (or leave blank for auto "analyze and respond").
   Result shown in popup; Ctrl+Shift+P to paste.

6. Ctrl+Shift+V - VOICE INPUT
   Start/stop voice recording. Transcribed text is appended to the overlay prompt.
   Then press Enter or Generate to get AI output.

7. Escape - CANCEL
   Close suggestion popup without pasting; clear state.

8. Ctrl+. - PAUSE / RESUME INJECTION
   While text is being typed by the app, pause or resume.

================================================================================

INSTALLATION & SETUP
--------------------

1. Prerequisites:
   - Node.js 16+
   - Python 3.7+
   - Windows (for full keystroke/window capture via pywin32)

2. Install Node dependencies:
   npm install
   (robotjs may need: npm run rebuild)

3. Install Python dependencies:
   pip install -r requirements.txt

4. Configure API keys (create .env from config.example.env):
   MISTRAL_API_KEY=your-mistral-key          # Required for text AI
   ANTHROPIC_API_KEY=your-anthropic-key      # Optional; for screenshot vision
   (Voice uses Google Speech Recognition - no key needed.)

5. Run:
   npm start

================================================================================

CONFIGURATION (.env)
--------------------

MISTRAL_API_KEY (required)
  - Text generation: overlay, grammar fix, extension, clipboard.
  - https://console.mistral.ai/api-keys/

ANTHROPIC_API_KEY (optional)
  - Screenshot + Vision (Ctrl+Shift+F).
  - https://console.anthropic.com/settings/keys

Voice uses Google Speech Recognition (free); no key required.

================================================================================

SETTINGS WINDOW
---------------

Open from tray or via shortcut if configured.

- Context mode: Use profile + app rules to adapt tone/length/style per app/URL.
  When you turn it on for the first time, you can create a profile (paste resume,
  set role, goals, tone). Stored in user_data/structured_key.json.

- Auto-inject: After generating, type/paste immediately (no suggestion popup).
  If OFF, you see the popup and press Ctrl+Shift+P to paste.

- Humanize: Variable typing speed and natural pauses when injecting (overlay
  toggle or settings).

App/URL rules (user_data/app_rules.json) define categories (chat, email, code,
document, browser, professional) and tone/length/style per app or URL pattern.
Context engine merges these with your profile to build the system prompt.

================================================================================

USAGE EXAMPLES
--------------

EXAMPLE 1: Overlay prompt
------------------------
Press Ctrl+Shift+Space. Type: "Write a short thank-you email for an interview."
Select tone, press Enter (or Generate). Result appears in popup. Press Ctrl+Shift+P
to paste at cursor. (If auto-inject is ON, pasting happens automatically.)

EXAMPLE 2: Grammar fix
---------------------
Type: "i went too the store and buyed some apples"
Press Ctrl+Alt+Enter
Result: Text is replaced with corrected version.

EXAMPLE 3: Continue writing (extension)
--------------------------------------
Type: "The quick brown fox"
Press Ctrl+Alt+Enter (fix if needed)
Within 2 seconds, press Ctrl+Alt+Enter again without typing
Result: AI continues e.g. "jumped over the lazy dog..."

EXAMPLE 4: Clipboard
--------------------
Copy some code. Press Ctrl+Shift+D. AI detects code and can fix/explain; result
injected at cursor. Or type "translate to French" then Ctrl+Shift+D with text
in clipboard; instruction applies to clipboard content.

EXAMPLE 5: Screenshot vision
----------------------------
Press Ctrl+Shift+F. Optionally type an instruction in the popup (e.g. "what
is the main topic?"). Screenshot is sent to Claude; result shown. Ctrl+Shift+P
to paste.

EXAMPLE 6: Voice
---------------
Press Ctrl+Shift+V (or click mic in overlay). Speak. Release or stop. Transcribed
text is added to the prompt field. Press Enter to generate.

EXAMPLE 7: Pause during injection
---------------------------------
AI is typing a long response. Press Ctrl+. to pause. Do something else. Press
Ctrl+. again to resume.

================================================================================

HUMANIZE TYPING
---------------

Toggle "Human" in the overlay (or in settings). When ON:
- Variable delay between keys (feels more natural)
- Optional typo simulation with quick correction
- Pause after punctuation

When OFF: minimal delay (fast injection).

================================================================================

PRIVACY
-------

- Keystroke monitor does NOT capture in: banking apps, payment apps, password
  managers, or windows with "password", "login", "payment" etc. in the title.
- Filtered content is not stored or sent to AI.
- Keylog (user_data / keylog.json) is used only as optional "memory" context
  when context mode is ON; entries are from non-private windows only.

================================================================================

FILE STRUCTURE
--------------

Electron / UI
  main.js              - Main process: windows, shortcuts, IPC, Python spawns
  renderer.js          - Overlay UI logic (prompt, generate, voice)
  settings_renderer.js - Settings window (profile, context, auto-inject)
  index.html           - Overlay UI
  settings.html        - Settings UI
  output.html          - Suggestion popup
  styles.css           - Styles

Python
  text_ai_backend.py   - Mistral text generation; context/memory when enabled
  context_engine.py    - Profile + app_rules → combined prompt
  profile_manager.py   - Resume parsing, system prompt, structured_key.json
  keystroke_monitor.py - Keystrokes, window tracking, triggers, keylog
  keyboard_inject.py   - Type/paste text (pynput); humanize; pause
  voice_transcribe.py  - Voice → text (Google Speech)
  screenshot_vision.py - Screenshot + Anthropic Vision

Data
  user_data/settings.json     - contextEnabled, autoInjectEnabled, humanizeEnabled
  user_data/structured_key.json - Profile + generated system_prompt
  user_data/app_rules.json    - App/URL → category and tone/length/style
  keylog.json                 - Recent typing (for memory when context ON)
  .env                        - API keys (gitignored)

Config / docs
  config.example.env, requirements.txt, package.json
  README.md, FALLBACK_MECHANISM.md, SETUP_GUIDE.txt, CODEBASE_OVERVIEW.md

================================================================================

ARCHITECTURE (simplified)
-------------------------

  [User] → Shortcuts / Overlay / Voice
       → main.js (Electron)
           → keystroke_monitor.py (buffer, window, app_category, memory)
           → text_ai_backend.py (prompt + context)
                 → context_engine.py (profile + app_rules) when context ON
                 → Mistral API
           → screenshot_vision.py (Ctrl+Shift+F) → Anthropic
           → voice_transcribe.py (Ctrl+Shift+V) → Google Speech
       → Result: popup and/or keyboard_inject.py (paste) + robotjs fallback

Flow: Trigger → main.js gathers context (app, memory if ON) → backend builds
prompt (with profile + app rules if context ON) → Mistral → JSON → inject or
show in popup → user pastes with Ctrl+Shift+P if auto-inject OFF.

================================================================================

TROUBLESHOOTING
---------------

Shortcuts not working?
  Some apps block global shortcuts. Run Electron with appropriate permissions.
  On Windows, robotjs may need rebuild: npm run rebuild.

AI returns preambles ("Here is...")?
  Prompts are tuned to avoid this. If context ON, check profile and app_rules.
  Check text_ai_backend.py and context_engine.py.

Keystroke monitor not capturing?
  Ensure no other app has exclusive keyboard hook. Restart app. On Windows,
  pywin32 must be installed for window detection.

Vision (Ctrl+Shift+F) not working?
  Set ANTHROPIC_API_KEY in .env.

Injection fails / wrong position?
  Fallback: app copies to clipboard and simulates Ctrl+V (robotjs). If robotjs
  fails, text is only copied; paste manually with Ctrl+V. See FALLBACK_MECHANISM.md.

Voice not working?
  Check microphone and that voice_transcribe.py runs (Google Speech Recognition;
  no API key). Ensure no other process is holding the mic.

================================================================================

VERSION NOTES
-------------

Current: Overlay + keystroke triggers + context mode (profile + app rules) +
auto-inject + settings window + screenshot vision (Anthropic) + voice (Google)
+ humanize + pause injection + privacy filters + clipboard with instruction.

================================================================================
